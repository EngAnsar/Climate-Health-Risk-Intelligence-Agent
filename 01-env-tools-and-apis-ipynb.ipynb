{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2562bcf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:38:07.879649Z",
     "iopub.status.busy": "2025-11-23T20:38:07.879250Z",
     "iopub.status.idle": "2025-11-23T20:38:10.181785Z",
     "shell.execute_reply": "2025-11-23T20:38:10.180563Z"
    },
    "papermill": {
     "duration": 2.309836,
     "end_time": "2025-11-23T20:38:10.183978",
     "exception": false,
     "start_time": "2025-11-23T20:38:07.874142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKDIR: /kaggle/working/env_resilience_agent\n",
      "Listing /kaggle/working (first 100 lines):\n",
      "total 32\r\n",
      "drwxr-xr-x 3 root root  4096 Nov 23 20:38 .\r\n",
      "drwxr-xr-x 8 root root  4096 Nov 23 20:37 ..\r\n",
      "drwxr-xr-x 2 root root  4096 Nov 23 20:38 env_resilience_agent\r\n",
      "---------- 1 root root 19616 Nov 23 20:38 __notebook__.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "# Cell1 - Notebook 1 - imports & setup\n",
    "# Cell 1: imports + workdir\n",
    "from pathlib import Path\n",
    "import os, json, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# where we'll store files\n",
    "WORKDIR = Path(\"/kaggle/working/env_resilience_agent\")\n",
    "WORKDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"WORKDIR:\", WORKDIR)\n",
    "print(\"Listing /kaggle/working (first 100 lines):\")\n",
    "!ls -la /kaggle/working | sed -n '1,120p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc7d3480",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:38:10.192504Z",
     "iopub.status.busy": "2025-11-23T20:38:10.191682Z",
     "iopub.status.idle": "2025-11-23T20:38:10.311261Z",
     "shell.execute_reply": "2025-11-23T20:38:10.310144Z"
    },
    "papermill": {
     "duration": 0.126018,
     "end_time": "2025-11-23T20:38:10.313321",
     "exception": false,
     "start_time": "2025-11-23T20:38:10.187303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AQICN_TOKEN: False\n",
      "OPENWEATHER_KEY: False\n",
      "OPENAI_KEY: True\n",
      "USE_LIVE_AQI: False USE_LIVE_WEATHER: False USE_LIVE_LLM: True\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: API keys and live/demo toggles\n",
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "us = UserSecretsClient()\n",
    "\n",
    "# Pull secrets from Kaggle vault\n",
    "os.environ[\"OPENAI_KEY\"] = us.get_secret(\"OPENAI_KEY\") or \"\"\n",
    "\n",
    "AQICN_TOKEN = os.environ.get(\"AQICN_TOKEN\")\n",
    "OPENWEATHER_KEY = os.environ.get(\"OPENWEATHER_KEY\")\n",
    "OPENAI_KEY = os.environ.get(\"OPENAI_KEY\")\n",
    "\n",
    "USE_LIVE_AQI = bool(AQICN_TOKEN)\n",
    "USE_LIVE_WEATHER = bool(OPENWEATHER_KEY)\n",
    "USE_LIVE_LLM = bool(OPENAI_KEY)\n",
    "\n",
    "print(\"AQICN_TOKEN:\", bool(AQICN_TOKEN))\n",
    "print(\"OPENWEATHER_KEY:\", bool(OPENWEATHER_KEY))\n",
    "print(\"OPENAI_KEY:\", bool(OPENAI_KEY))\n",
    "print(\"USE_LIVE_AQI:\", USE_LIVE_AQI, \"USE_LIVE_WEATHER:\", USE_LIVE_WEATHER, \"USE_LIVE_LLM:\", USE_LIVE_LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a7836b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:38:10.321011Z",
     "iopub.status.busy": "2025-11-23T20:38:10.320663Z",
     "iopub.status.idle": "2025-11-23T20:38:10.331351Z",
     "shell.execute_reply": "2025-11-23T20:38:10.330338Z"
    },
    "papermill": {
     "duration": 0.016404,
     "end_time": "2025-11-23T20:38:10.332864",
     "exception": false,
     "start_time": "2025-11-23T20:38:10.316460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 3: AQICN & OpenWeather helpers (safe â€” return None if keys not present)\n",
    "import requests, math\n",
    "\n",
    "def fetch_aqi_city(city):\n",
    "    \"\"\"Try AQICN live, else return None (we will fallback later).\"\"\"\n",
    "    if not USE_LIVE_AQI:\n",
    "        return None\n",
    "    try:\n",
    "        url = f\"https://api.waqi.info/feed/{city}/?token={AQICN_TOKEN}\"\n",
    "        r = requests.get(url, timeout=10)\n",
    "        if r.status_code != 200:\n",
    "            return None\n",
    "        j = r.json()\n",
    "        if j.get(\"status\") != \"ok\":\n",
    "            return None\n",
    "        data = j.get(\"data\", {})\n",
    "        return {\n",
    "            \"aqi\": data.get(\"aqi\"),\n",
    "            \"dominantpol\": data.get(\"dominantpol\"),\n",
    "            \"time\": data.get(\"time\", {}).get(\"s\"),\n",
    "            \"city\": data.get(\"city\",{}).get(\"name\")\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(\"AQI fetch error:\", e)\n",
    "        return None\n",
    "\n",
    "def fetch_weather_city(city):\n",
    "    \"\"\"Try OpenWeather live, else return None\"\"\"\n",
    "    if not USE_LIVE_WEATHER:\n",
    "        return None\n",
    "    try:\n",
    "        params = {\"q\": city, \"appid\": OPENWEATHER_KEY, \"units\": \"metric\"}\n",
    "        url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "        r = requests.get(url, params=params, timeout=10)\n",
    "        if r.status_code != 200:\n",
    "            return None\n",
    "        j = r.json()\n",
    "        # minimal safe extraction\n",
    "        main = j.get(\"main\", {})\n",
    "        wind = j.get(\"wind\", {})\n",
    "        weather = (j.get(\"weather\") or [{}])[0]\n",
    "        return {\n",
    "            \"temp\": main.get(\"temp\"),\n",
    "            \"feels_like\": main.get(\"feels_like\"),\n",
    "            \"humidity\": main.get(\"humidity\"),\n",
    "            \"wind_speed\": wind.get(\"speed\"),\n",
    "            \"descr\": weather.get(\"description\")\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(\"OpenWeather fetch error:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f8434de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:38:10.341152Z",
     "iopub.status.busy": "2025-11-23T20:38:10.340388Z",
     "iopub.status.idle": "2025-11-23T20:38:10.346406Z",
     "shell.execute_reply": "2025-11-23T20:38:10.345227Z"
    },
    "papermill": {
     "duration": 0.011887,
     "end_time": "2025-11-23T20:38:10.348086",
     "exception": false,
     "start_time": "2025-11-23T20:38:10.336199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AQI fetch (synthetic fallback expected):\n",
      "None\n",
      "\n",
      "Testing Weather fetch (synthetic fallback expected):\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Test if helper functions work (demo mode)\n",
    "print(\"Testing AQI fetch (synthetic fallback expected):\")\n",
    "print(fetch_aqi_city(\"Lucknow\"))\n",
    "\n",
    "print(\"\\nTesting Weather fetch (synthetic fallback expected):\")\n",
    "print(fetch_weather_city(\"Lucknow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "845c0156",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:38:10.356093Z",
     "iopub.status.busy": "2025-11-23T20:38:10.355706Z",
     "iopub.status.idle": "2025-11-23T20:38:10.530517Z",
     "shell.execute_reply": "2025-11-23T20:38:10.529307Z"
    },
    "papermill": {
     "duration": 0.181002,
     "end_time": "2025-11-23T20:38:10.532408",
     "exception": false,
     "start_time": "2025-11-23T20:38:10.351406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data saved:\n",
      "total 48\r\n",
      "drwxr-xr-x 2 root root  4096 Nov 23 20:38 .\r\n",
      "drwxr-xr-x 3 root root  4096 Nov 23 20:38 ..\r\n",
      "-rw-r--r-- 1 root root  1007 Nov 23 20:38 aqi.csv\r\n",
      "-rw-r--r-- 1 root root  2828 Nov 23 20:38 complaints.csv\r\n",
      "-rw-r--r-- 1 root root 32343 Nov 23 20:38 ndvi_grid.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Cell4 - OpenWeather helper\n",
    "\n",
    "# Cell 4: generate and save synthetic CSVs (aqi.csv, ndvi_grid.csv, complaints.csv)\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# 1) aqi.csv (30 days history)\n",
    "days = 30\n",
    "dates = pd.date_range(end=pd.Timestamp.today(), periods=days)\n",
    "aqi_vals = rng.normal(loc=80, scale=25, size=days).clip(20,300).astype(int)\n",
    "aqi_df = pd.DataFrame({\"date\": dates, \"aqi\": aqi_vals})\n",
    "aqi_df[\"pm25\"] = (aqi_df[\"aqi\"] * 0.6 + rng.normal(0,5,size=days)).round().astype(int)\n",
    "aqi_df.to_csv(WORKDIR/\"aqi.csv\", index=False)\n",
    "\n",
    "# 2) ndvi_grid.csv (grid points)\n",
    "nx, ny = 30, 20\n",
    "grid = rng.uniform(0.05, 0.6, size=(ny, nx))\n",
    "lats = np.linspace(26.8, 27.0, ny)\n",
    "lons = np.linspace(80.9, 81.1, nx)\n",
    "rows = []\n",
    "for i,lat in enumerate(lats):\n",
    "    for j,lon in enumerate(lons):\n",
    "        rows.append({\"lat\": float(lat), \"lon\": float(lon), \"ndvi\": float(grid[i,j])})\n",
    "ndvi_df = pd.DataFrame(rows)\n",
    "ndvi_df.to_csv(WORKDIR/\"ndvi_grid.csv\", index=False)\n",
    "\n",
    "# 3) complaints.csv (sample text complaints)\n",
    "texts = [\n",
    "  \"Overflowing garbage near market\",\"Open burning in sector 5\",\n",
    "  \"Dust and smog during morning hours\",\"Uncollected trash near bus stop\",\n",
    "  \"Construction dust near river\",\"Smell of burning plastic near lane\",\"No greenery near school\"\n",
    "]\n",
    "complaints = []\n",
    "for i in range(40):\n",
    "    complaints.append({\n",
    "        \"id\": i,\n",
    "        \"text\": rng.choice(texts),\n",
    "        \"lat\": 26.85 + rng.rand()*0.1,\n",
    "        \"lon\": 80.95 + rng.rand()*0.1\n",
    "    })\n",
    "complaints_df = pd.DataFrame(complaints)\n",
    "complaints_df.to_csv(WORKDIR/\"complaints.csv\", index=False)\n",
    "\n",
    "print(\"Synthetic data saved:\")\n",
    "!ls -la /kaggle/working/env_resilience_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d979f50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:38:10.540757Z",
     "iopub.status.busy": "2025-11-23T20:38:10.539934Z",
     "iopub.status.idle": "2025-11-23T20:38:10.573146Z",
     "shell.execute_reply": "2025-11-23T20:38:10.571936Z"
    },
    "papermill": {
     "duration": 0.039349,
     "end_time": "2025-11-23T20:38:10.574896",
     "exception": false,
     "start_time": "2025-11-23T20:38:10.535547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> aqi.csv exists: True\n",
      "                         date  aqi  pm25\n",
      "0  2025-10-25 20:38:10.366785   92    52\n",
      "1  2025-10-26 20:38:10.366785   76    55\n",
      "2  2025-10-27 20:38:10.366785   96    58\n",
      "3  2025-10-28 20:38:10.366785  118    66\n",
      "4  2025-10-29 20:38:10.366785   74    49 \n",
      "\n",
      "-> ndvi_grid.csv exists: True\n",
      "    lat        lon      ndvi\n",
      "0  26.8  80.900000  0.231994\n",
      "1  26.8  80.906897  0.084957\n",
      "2  26.8  80.913793  0.221040\n",
      "3  26.8  80.920690  0.228851\n",
      "4  26.8  80.927586  0.451283 \n",
      "\n",
      "-> complaints.csv exists: True\n",
      "   id                                text        lat        lon\n",
      "0   0  Smell of burning plastic near lane  26.916864  81.042938\n",
      "1   1             No greenery near school  26.903504  80.997662\n",
      "2   2        Construction dust near river  26.926949  80.968704\n",
      "3   3  Smell of burning plastic near lane  26.921095  80.969951\n",
      "4   4     Uncollected trash near bus stop  26.874241  80.961484 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: quick read & show heads so you see outputs immediately\n",
    "import pandas as pd, pathlib\n",
    "p = pathlib.Path(\"/kaggle/working/env_resilience_agent\")\n",
    "\n",
    "for fname in [\"aqi.csv\", \"ndvi_grid.csv\", \"complaints.csv\"]:\n",
    "    fp = p/fname\n",
    "    print(\"->\", fname, \"exists:\", fp.exists())\n",
    "    if fp.exists():\n",
    "        if fname.endswith(\".csv\"):\n",
    "            print(pd.read_csv(fp).head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58375151",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:38:10.583344Z",
     "iopub.status.busy": "2025-11-23T20:38:10.582860Z",
     "iopub.status.idle": "2025-11-23T20:38:10.588999Z",
     "shell.execute_reply": "2025-11-23T20:38:10.588114Z"
    },
    "papermill": {
     "duration": 0.012287,
     "end_time": "2025-11-23T20:38:10.590737",
     "exception": false,
     "start_time": "2025-11-23T20:38:10.578450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files present. Ready.\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: safe recreate fallback if any file missing (runs only if needed)\n",
    "from pathlib import Path\n",
    "p = Path(\"/kaggle/working/env_resilience_agent\")\n",
    "missing = [f for f in [\"aqi.csv\",\"ndvi_grid.csv\",\"complaints.csv\"] if not (p/f).exists()]\n",
    "if missing:\n",
    "    print(\"Missing files:\", missing, \" --> recreating synthetic files now.\")\n",
    "    # paste same generator code (or call function). For brevity, re-run Cell4 code here:\n",
    "    # (We will call the generator function block again)\n",
    "    # For simplicity we just call the previous code by re-executing it: run Cell 4 again manually if needed.\n",
    "else:\n",
    "    print(\"All files present. Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6adb18c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:38:10.599364Z",
     "iopub.status.busy": "2025-11-23T20:38:10.598777Z",
     "iopub.status.idle": "2025-11-23T20:38:10.655422Z",
     "shell.execute_reply": "2025-11-23T20:38:10.654301Z"
    },
    "papermill": {
     "duration": 0.06288,
     "end_time": "2025-11-23T20:38:10.657042",
     "exception": false,
     "start_time": "2025-11-23T20:38:10.594162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AQI processed rows: 30\n",
      "Forecast rows saved: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/1290078029.py:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aqi_raw[\"aqi\"] = pd.to_numeric(aqi_raw[\"aqi\"], errors=\"coerce\").fillna(method=\"ffill\").astype(int)\n",
      "/tmp/ipykernel_13/1290078029.py:14: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aqi_raw[\"pm25\"] = pd.to_numeric(aqi_raw.get(\"pm25\", pd.Series()), errors=\"coerce\").fillna(method=\"ffill\").astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Cell7 - Forecast helper (AQI)\n",
    "\n",
    "# Cell 7: process AQI history and create a simple short-term forecast\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "WORKDIR = Path(\"/kaggle/working/env_resilience_agent\")\n",
    "\n",
    "# read raw aqi\n",
    "aqi_raw = pd.read_csv(WORKDIR/\"aqi.csv\", parse_dates=[\"date\"])\n",
    "aqi_raw = aqi_raw.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# basic cleaning\n",
    "aqi_raw[\"aqi\"] = pd.to_numeric(aqi_raw[\"aqi\"], errors=\"coerce\").fillna(method=\"ffill\").astype(int)\n",
    "aqi_raw[\"pm25\"] = pd.to_numeric(aqi_raw.get(\"pm25\", pd.Series()), errors=\"coerce\").fillna(method=\"ffill\").astype(int)\n",
    "\n",
    "# aggregated daily stats (already daily but keep pattern)\n",
    "aqi_daily = aqi_raw.groupby(aqi_raw[\"date\"].dt.date).agg(\n",
    "    aqi_mean=(\"aqi\",\"mean\"),\n",
    "    aqi_max=(\"aqi\",\"max\"),\n",
    "    pm25_mean=(\"pm25\",\"mean\")\n",
    ").reset_index().rename(columns={\"date\":\"day\"})\n",
    "aqi_daily[\"day\"] = pd.to_datetime(aqi_daily[\"day\"])\n",
    "\n",
    "# simple forecast: 7-day moving average shifted forward 1 day as naive forecast\n",
    "aqi_daily[\"ma7\"] = aqi_daily[\"aqi_mean\"].rolling(7, min_periods=1).mean()\n",
    "# create forecast rows for next 3 days\n",
    "last_date = aqi_daily[\"day\"].max()\n",
    "forecast_horizon = 3\n",
    "fcast_rows = []\n",
    "last_ma = aqi_daily[\"ma7\"].iloc[-1]\n",
    "for i in range(1, forecast_horizon+1):\n",
    "    fdate = last_date + pd.Timedelta(days=i)\n",
    "    # simple model: trend = difference of last two means\n",
    "    trend = (aqi_daily[\"aqi_mean\"].iloc[-1] - aqi_daily[\"aqi_mean\"].iloc[-2]) if len(aqi_daily) > 1 else 0\n",
    "    pred = max(0, int(round(last_ma + trend * 0.5)))\n",
    "    fcast_rows.append({\"date\": fdate, \"pred_aqi\": pred})\n",
    "fcast_df = pd.DataFrame(fcast_rows)\n",
    "\n",
    "# save processed outputs\n",
    "aqi_daily.to_csv(WORKDIR/\"aqi_history_processed.csv\", index=False)\n",
    "fcast_df.to_csv(WORKDIR/\"aqi_forecast.csv\", index=False)\n",
    "\n",
    "print(\"AQI processed rows:\", len(aqi_daily))\n",
    "print(\"Forecast rows saved:\", len(fcast_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e953b0f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:38:10.665982Z",
     "iopub.status.busy": "2025-11-23T20:38:10.665617Z",
     "iopub.status.idle": "2025-11-23T20:38:10.696775Z",
     "shell.execute_reply": "2025-11-23T20:38:10.695661Z"
    },
    "papermill": {
     "duration": 0.037761,
     "end_time": "2025-11-23T20:38:10.698615",
     "exception": false,
     "start_time": "2025-11-23T20:38:10.660854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI overall: 0.3235\n",
      "NDVI row summary rows: 20\n",
      "Complaints agg rows: 30\n",
      "Top complaint texts: {'Dust and smog during morning hours': 8, 'Smell of burning plastic near lane': 7, 'Construction dust near river': 7, 'Uncollected trash near bus stop': 6, 'Open burning in sector 5': 6}\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: create NDVI summary (mean per coarse tile) and complaints summary\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "WORKDIR = Path(\"/kaggle/working/env_resilience_agent\")\n",
    "\n",
    "# NDVI grid read & simple heatmap-ready aggregation\n",
    "ndvi = pd.read_csv(WORKDIR/\"ndvi_grid.csv\")\n",
    "# compute mean NDVI across whole grid and per-row summary\n",
    "ndvi_overall = ndvi[\"ndvi\"].mean()\n",
    "ndvi_row = ndvi.groupby(np.round(ndvi[\"lat\"], 3)).agg(ndvi_mean=(\"ndvi\",\"mean\")).reset_index().rename(columns={\"lat\":\"lat_approx\"})\n",
    "\n",
    "# complaints read & nearest-count per coarse lat/lon cell\n",
    "complaints = pd.read_csv(WORKDIR/\"complaints.csv\")\n",
    "# rough spatial bin by rounding coordinates\n",
    "complaints[\"lat_bin\"] = complaints[\"lat\"].round(2)\n",
    "complaints[\"lon_bin\"] = complaints[\"lon\"].round(2)\n",
    "complaints_agg = complaints.groupby([\"lat_bin\",\"lon_bin\"]).size().reset_index(name=\"count\")\n",
    "# top complaint texts sample\n",
    "top_texts = complaints[\"text\"].value_counts().head(5).to_dict()\n",
    "\n",
    "# Save results for Notebook-2 use\n",
    "pd.DataFrame([{\"ndvi_overall\": float(ndvi_overall)}]).to_csv(WORKDIR/\"ndvi_overall.csv\", index=False)\n",
    "ndvi_row.to_csv(WORKDIR/\"ndvi_row_summary.csv\", index=False)\n",
    "complaints_agg.to_csv(WORKDIR/\"complaints_agg.csv\", index=False)\n",
    "pd.DataFrame([{\"top_texts\": str(top_texts)}]).to_csv(WORKDIR/\"complaints_summary.csv\", index=False)\n",
    "\n",
    "print(\"NDVI overall:\", round(ndvi_overall,4))\n",
    "print(\"NDVI row summary rows:\", len(ndvi_row))\n",
    "print(\"Complaints agg rows:\", len(complaints_agg))\n",
    "print(\"Top complaint texts:\", top_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa2c50a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T20:38:10.707598Z",
     "iopub.status.busy": "2025-11-23T20:38:10.707255Z",
     "iopub.status.idle": "2025-11-23T20:38:10.716786Z",
     "shell.execute_reply": "2025-11-23T20:38:10.715701Z"
    },
    "papermill": {
     "duration": 0.016093,
     "end_time": "2025-11-23T20:38:10.718465",
     "exception": false,
     "start_time": "2025-11-23T20:38:10.702372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in WORKDIR now:\n",
      "- aqi.csv\n",
      "- aqi_forecast.csv\n",
      "- aqi_history_processed.csv\n",
      "- complaints.csv\n",
      "- complaints_agg.csv\n",
      "- complaints_summary.csv\n",
      "- ndvi_grid.csv\n",
      "- ndvi_overall.csv\n",
      "- ndvi_row_summary.csv\n",
      "\n",
      "Metadata written to: /kaggle/working/env_resilience_agent/metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: final verify and optional save a small metadata file (used in writeup)\n",
    "from pathlib import Path\n",
    "import json\n",
    "WORKDIR = Path(\"/kaggle/working/env_resilience_agent\")\n",
    "\n",
    "files = sorted([p.name for p in WORKDIR.iterdir()])\n",
    "meta = {\n",
    "    \"created_at\": pd.Timestamp.now().isoformat(),\n",
    "    \"files\": files,\n",
    "    \"author\": \"Ansar Ahmad\",\n",
    "    \"notebook\": \"01_data_setup.ipynb\"\n",
    "}\n",
    "with open(WORKDIR/\"metadata.json\",\"w\",encoding=\"utf8\") as f:\n",
    "    json.dump(meta,f,indent=2)\n",
    "\n",
    "print(\"Files in WORKDIR now:\")\n",
    "for f in files:\n",
    "    print(\"-\", f)\n",
    "print(\"\\nMetadata written to:\", WORKDIR/\"metadata.json\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14484960,
     "sourceId": 121144,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.559196,
   "end_time": "2025-11-23T20:38:11.243417",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-23T20:38:02.684221",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
